# üìö Documentaci√≥n Completa del Proyecto CIFAR-10 MLP Classifier

---

## üìã Tabla de Contenidos
1. [Visi√≥n General del Proyecto](#visi√≥n-general-del-proyecto)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Estructura de Archivos](#estructura-de-archivos)
4. [An√°lisis Detallado de Cada Archivo](#an√°lisis-detallado-de-cada-archivo)
5. [Flujo de Datos](#flujo-de-datos)
6. [Conceptos Importantes](#conceptos-importantes)
7. [Instalaci√≥n y Uso](#instalaci√≥n-y-uso)

---

## üéØ Visi√≥n General del Proyecto

### Objetivo
Este proyecto implementa un clasificador de im√°genes utilizando una **Red Neuronal Artificial (MLP - Multi-Layer Perceptron)** entrenada sobre el dataset CIFAR-10, espec√≠ficamente para clasificar 4 categor√≠as de im√°genes:
- **Airplane** (Avi√≥n)
- **Automobile** (Autom√≥vil)
- **Ship** (Barco)
- **Truck** (Cami√≥n)

### Tecnolog√≠as Principales
- **PyTorch**: Framework de deep learning para entrenar el modelo
- **FastAPI**: Backend API REST para servir predicciones
- **React**: Frontend web para interfaz de usuario
- **Docker**: Containerizaci√≥n para facilitar el despliegue

### Caracter√≠sticas Clave
- ‚úÖ Modelo MLP simple pero efectivo (~68% accuracy en test)
- ‚úÖ API REST para predicciones en tiempo real
- ‚úÖ Interfaz web intuitiva con dos modos de clasificaci√≥n
- ‚úÖ Procesamiento autom√°tico de im√°genes de cualquier tama√±o
- ‚úÖ Sistema completamente dockerizado

---

## üèóÔ∏è Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USUARIO                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Frontend (React)      ‚îÇ
              ‚îÇ   Puerto: 3000          ‚îÇ
              ‚îÇ   - Carga de im√°genes   ‚îÇ
              ‚îÇ   - Visualizaci√≥n       ‚îÇ
              ‚îÇ   - Resultados          ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ HTTP POST /predict
                         ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  Backend (FastAPI)      ‚îÇ
              ‚îÇ  Puerto: 8000           ‚îÇ
              ‚îÇ  - Recibe imagen        ‚îÇ
              ‚îÇ  - Preprocesa           ‚îÇ
              ‚îÇ  - Inferencia           ‚îÇ
              ‚îÇ  - Retorna resultado    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  Modelo MLP (PyTorch)   ‚îÇ
              ‚îÇ  cifar10_mlp.pth        ‚îÇ
              ‚îÇ  - 1.7M par√°metros      ‚îÇ
              ‚îÇ  - 3 capas              ‚îÇ
              ‚îÇ  - 4 clases salida      ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              DOCKER COMPOSE ORCHESTRATION                    ‚îÇ
‚îÇ  - Red compartida: cifar10-network                          ‚îÇ
‚îÇ  - Volumen compartido: ./model                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Estructura de Archivos

```
cifar10/
‚îÇ
‚îú‚îÄ‚îÄ üìä data/                              # Datos del dataset
‚îÇ   ‚îú‚îÄ‚îÄ cifar10_original/                 # Dataset original descargado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cifar-10-batches-py/          # Archivos binarios de CIFAR-10
‚îÇ   ‚îú‚îÄ‚îÄ train/                            # 19,200 im√°genes de entrenamiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ airplane/                     # ~4,800 im√°genes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ automobile/                   # ~4,800 im√°genes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ship/                         # ~4,800 im√°genes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ truck/                        # ~4,800 im√°genes
‚îÇ   ‚îú‚îÄ‚îÄ test/                             # 4,800 im√°genes de prueba
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ airplane/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ automobile/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ship/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ truck/
‚îÇ   ‚îî‚îÄ‚îÄ sample_images/                    # 40 im√°genes de muestra (10 por clase)
‚îÇ
‚îú‚îÄ‚îÄ üß† model/                             # Modelo de red neuronal
‚îÇ   ‚îú‚îÄ‚îÄ mlp_model.py                      # Definici√≥n de la arquitectura MLP
‚îÇ   ‚îú‚îÄ‚îÄ train.py                          # Script de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ cifar10_mlp.pth                   # Modelo entrenado (pesos guardados)
‚îÇ   ‚îî‚îÄ‚îÄ training_metrics.json             # M√©tricas del entrenamiento
‚îÇ
‚îú‚îÄ‚îÄ üîß backend/                           # API Backend
‚îÇ   ‚îú‚îÄ‚îÄ main.py                           # Servidor FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                  # Dependencias Python
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile                        # Containerizaci√≥n del backend
‚îÇ
‚îú‚îÄ‚îÄ üé® frontend/                          # Interfaz Web
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.js                        # Componente principal React
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.js                      # Punto de entrada
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html                    # HTML base
‚îÇ   ‚îú‚îÄ‚îÄ package.json                      # Dependencias Node.js
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile                        # Containerizaci√≥n del frontend
‚îÇ
‚îú‚îÄ‚îÄ üìà plots/                             # Gr√°ficas del entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ training_curves.png               # Loss y Accuracy por epoch
‚îÇ   ‚îî‚îÄ‚îÄ final_metrics.png                 # Resumen de m√©tricas finales
‚îÇ
‚îú‚îÄ‚îÄ üê≥ docker-compose.yml                 # Orquestaci√≥n de contenedores
‚îú‚îÄ‚îÄ üî® prepare_dataset.py                 # Script para preparar el dataset
‚îú‚îÄ‚îÄ üìñ PLAN.md                            # Plan de implementaci√≥n
‚îî‚îÄ‚îÄ üìö DOCUMENTACION.md                   # Este archivo
```

---

## üîç An√°lisis Detallado de Cada Archivo

---

### 1Ô∏è‚É£ `prepare_dataset.py` - Preparaci√≥n del Dataset

**Prop√≥sito**: Descarga, filtra y organiza el dataset CIFAR-10 para el entrenamiento.

#### üîë Funciones Principales

```python
# Descarga del dataset completo (50,000 im√°genes)
full_dataset = datasets.CIFAR10(root='./data/cifar10_original', 
                                train=True, download=True)
```

**¬øQu√© hace?**
- Descarga autom√°ticamente CIFAR-10 si no existe
- CIFAR-10 original tiene 10 clases, pero solo necesitamos 4

#### üìä Proceso de Filtrado

```python
SELECTED_CLASSES = {
    0: 'airplane',
    1: 'automobile',
    8: 'ship',
    9: 'truck'
}
```

**¬øPor qu√© estos √≠ndices?**
- CIFAR-10 usa √≠ndices espec√≠ficos para cada clase
- Clase 0 = airplane, Clase 1 = automobile
- Clase 8 = ship, Clase 9 = truck
- Se filtran ~24,000 im√°genes totales (~6,000 por clase)

#### üîÑ Divisi√≥n de Datos

```python
split_point = int(0.8 * len(selected_indices))
train_indices = selected_indices[:split_point]  # 80%
test_indices = selected_indices[split_point:]   # 20%
```

**Concepto Importante: Train/Test Split**
- **Train (80%)**: 19,200 im√°genes para entrenar el modelo
- **Test (20%)**: 4,800 im√°genes para evaluar el rendimiento
- Esta divisi√≥n evita el **overfitting** (que el modelo memorice en vez de aprender)

#### üíæ Guardado de Im√°genes

```python
def save_images(indices, folder_name):
    for idx in indices:
        img, label = full_dataset[idx]
        class_name = SELECTED_CLASSES[label]
        class_folder = os.path.join(folder_name, class_name)
        img_path = os.path.join(class_folder, f"{idx}.png")
        img.save(img_path)
```

**Organizaci√≥n**:
- Cada imagen se guarda en su carpeta de clase correspondiente
- Formato PNG para preservar calidad
- Nombres √∫nicos usando el √≠ndice original

#### üéØ Muestras de Prueba

```python
# 10 im√°genes de cada clase -> sample_images/
samples_per_class[label].append(idx)
```

**Utilidad**:
- 40 im√°genes totales para pruebas manuales r√°pidas
- Facilita verificar que el modelo funciona correctamente
- No se usan en entrenamiento ni evaluaci√≥n

---

### 2Ô∏è‚É£ `model/mlp_model.py` - Arquitectura de la Red Neuronal

**Prop√≥sito**: Define la estructura del Multi-Layer Perceptron (MLP).

#### üß† Arquitectura del Modelo

```python
class MLP(nn.Module):
    def __init__(self, input_size=3072, hidden1=512, hidden2=256, num_classes=4):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden1)    # 3072 -> 512
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(hidden1, hidden2)       # 512 -> 256
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(hidden2, num_classes)   # 256 -> 4
```

**Desglose Capa por Capa**:

1. **Capa de Entrada (fc1)**:
   - **Input**: 3072 neuronas (32x32x3 = imagen RGB aplanada)
   - **Output**: 512 neuronas
   - **Par√°metros**: 3072 √ó 512 + 512 (bias) = 1,573,376
   - **Funci√≥n**: Extrae caracter√≠sticas b√°sicas de la imagen

2. **Activaci√≥n ReLU (relu1)**:
   ```python
   ReLU(x) = max(0, x)
   ```
   - **Prop√≥sito**: Introduce no-linealidad
   - **Sin ReLU**: La red solo podr√≠a aprender relaciones lineales
   - **Con ReLU**: Puede aprender patrones complejos

3. **Capa Oculta (fc2)**:
   - **Input**: 512 neuronas
   - **Output**: 256 neuronas
   - **Par√°metros**: 512 √ó 256 + 256 = 131,328
   - **Funci√≥n**: Combina caracter√≠sticas en representaciones m√°s abstractas

4. **Activaci√≥n ReLU (relu2)**: Otra capa de no-linealidad

5. **Capa de Salida (fc3)**:
   - **Input**: 256 neuronas
   - **Output**: 4 neuronas (una por clase)
   - **Par√°metros**: 256 √ó 4 + 4 = 1,028
   - **Funci√≥n**: Produce puntuaciones (logits) para cada clase

**Total de Par√°metros**: 1,705,732

#### üîÑ Forward Pass

```python
def forward(self, x):
    x = x.view(x.size(0), -1)  # Aplanar imagen
    x = self.fc1(x)
    x = self.relu1(x)
    x = self.fc2(x)
    x = self.relu2(x)
    x = self.fc3(x)
    return x
```

**Flujo de Datos**:
```
Imagen [batch, 3, 32, 32]
    ‚Üì view()
Vector [batch, 3072]
    ‚Üì fc1 + relu1
Vector [batch, 512]
    ‚Üì fc2 + relu2
Vector [batch, 256]
    ‚Üì fc3
Logits [batch, 4]
```

**Concepto Importante: Batch Processing**
- `batch` = n√∫mero de im√°genes procesadas simult√°neamente
- Batch size de 64 significa 64 im√°genes a la vez
- M√°s eficiente que procesar una por una

#### üìä Informaci√≥n del Modelo

```python
def get_model_info(self):
    total_params = sum(p.numel() for p in self.parameters())
    trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
```

**¬øQu√© son los par√°metros entrenables?**
- Pesos y biases que la red ajusta durante el entrenamiento
- En este modelo, todos los par√°metros son entrenables
- Algunos modelos congelan capas (transfer learning)

---

### 3Ô∏è‚É£ `model/train.py` - Script de Entrenamiento

**Prop√≥sito**: Entrena el modelo MLP con los datos preparados.

#### ‚öôÔ∏è Configuraci√≥n de Hiperpar√°metros

```python
BATCH_SIZE = 64
LEARNING_RATE = 0.001
NUM_EPOCHS = 25
```

**Explicaci√≥n de Hiperpar√°metros**:

- **BATCH_SIZE = 64**:
  - Procesa 64 im√°genes simult√°neamente
  - Trade-off: M√°s grande = m√°s r√°pido pero m√°s memoria
  - 64 es un valor est√°ndar y eficiente

- **LEARNING_RATE = 0.001**:
  - Controla qu√© tan r√°pido aprende el modelo
  - Muy alto ‚Üí el modelo puede no converger
  - Muy bajo ‚Üí entrenamiento muy lento
  - 0.001 (1e-3) es un valor com√∫n para Adam

- **NUM_EPOCHS = 25**:
  - Una √©poca = pasar por TODO el dataset una vez
  - 25 √©pocas = el modelo ve cada imagen 25 veces
  - M√°s √©pocas ‚â† siempre mejor (riesgo de overfitting)

#### üìÇ Dataset Personalizado

```python
class CIFAR10CustomDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.class_to_idx = {name: idx for idx, name in enumerate(CLASS_NAMES)}
        
        for class_name in CLASS_NAMES:
            class_dir = os.path.join(root_dir, class_name)
            for img_name in os.listdir(class_dir):
                self.images.append(img_path)
                self.labels.append(self.class_to_idx[class_name])
```

**¬øPor qu√© un Dataset personalizado?**
- PyTorch necesita saber c√≥mo cargar nuestros datos
- Conecta archivos de imagen con sus etiquetas
- Aplica transformaciones autom√°ticamente

#### üîÑ Transformaciones

```python
transform = transforms.Compose([
    transforms.ToTensor(),                           # PIL -> Tensor
    transforms.Normalize((0.5, 0.5, 0.5),           # Media RGB
                        (0.5, 0.5, 0.5))            # Std RGB
])
```

**¬øPor qu√© normalizar?**
1. **ToTensor**: Convierte PIL Image a tensor PyTorch [0, 1]
2. **Normalize**: Escala a [-1, 1]
   ```
   normalized = (pixel - mean) / std
   normalized = (pixel - 0.5) / 0.5
   ```
3. **Beneficio**: Acelera el entrenamiento y mejora convergencia

#### üéØ DataLoader

```python
train_loader = DataLoader(dataset=train_dataset, 
                         batch_size=BATCH_SIZE,
                         shuffle=True,           # Importante!
                         num_workers=0)
```

**Concepto Importante: Shuffle**
- **shuffle=True** en train: Aleatoriza el orden en cada √©poca
- Previene que el modelo aprenda el orden de los datos
- **shuffle=False** en test: No necesario, solo evaluamos

#### üí™ Optimizador y Loss Function

```python
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
```

**CrossEntropyLoss**:
- Funci√≥n de p√©rdida para clasificaci√≥n multi-clase
- Combina LogSoftmax + NLLLoss
- Penaliza predicciones incorrectas
- F√≥rmula: `Loss = -log(P(clase_correcta))`

**Adam Optimizer**:
- Algoritmo de optimizaci√≥n adaptativo
- Ajusta el learning rate autom√°ticamente
- Mejor que SGD simple para muchos casos
- Combina momentum + RMSProp

#### üîÅ Loop de Entrenamiento

```python
for epoch in range(NUM_EPOCHS):
    model.train()  # Modo entrenamiento
    
    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)
        
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # Backward pass
        optimizer.zero_grad()  # Limpiar gradientes anteriores
        loss.backward()         # Calcular gradientes
        optimizer.step()        # Actualizar pesos
```

**Desglose del Training Loop**:

1. **model.train()**: Activa modo entrenamiento
   - Importante para Dropout y BatchNorm (no usados aqu√≠)
   - Buena pr√°ctica siempre ponerlo

2. **Forward Pass**:
   ```python
   outputs = model(images)  # Predicciones
   loss = criterion(outputs, labels)  # Calcular error
   ```

3. **Backward Pass** (Backpropagation):
   ```python
   optimizer.zero_grad()  # Resetear gradientes
   loss.backward()         # Calcular ‚àÇLoss/‚àÇWeights
   optimizer.step()        # weights = weights - lr * gradient
   ```

**Concepto Crucial: Backpropagation**
- Calcula c√≥mo cada peso contribuye al error
- Usa la regla de la cadena (c√°lculo)
- Permite ajustar pesos para reducir el error

#### üìä Evaluaci√≥n

```python
def evaluate_model(model, data_loader, criterion, device):
    model.eval()  # Modo evaluaci√≥n
    with torch.no_grad():  # No calcular gradientes
        for images, labels in data_loader:
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()
    
    accuracy = 100 * correct / total
```

**¬øPor qu√© model.eval() y no_grad()?**
- **model.eval()**: Desactiva Dropout, BatchNorm en modo eval
- **torch.no_grad()**: Ahorra memoria, no necesitamos gradientes
- Combinados: Evaluaci√≥n m√°s r√°pida y precisa

#### üíæ Guardado del Modelo

```python
torch.save({
    'epoch': NUM_EPOCHS,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'train_loss': train_losses[-1],
    'test_loss': test_losses[-1],
    'train_accuracy': train_accuracies[-1],
    'test_accuracy': test_accuracies[-1],
    'class_names': CLASS_NAMES,
    'input_size': INPUT_SIZE,
    'hidden1': HIDDEN1,
    'hidden2': HIDDEN2,
    'num_classes': NUM_CLASSES,
}, model_path)
```

**¬øQu√© se guarda?**
- **model_state_dict**: Todos los pesos y biases
- **optimizer_state_dict**: Estado del optimizador (por si queremos continuar entrenando)
- **Hiperpar√°metros**: Para reconstruir el modelo exactamente
- **M√©tricas**: Para referencia futura

#### üìà Visualizaci√≥n de M√©tricas

```python
# Loss curves
plt.plot(range(1, NUM_EPOCHS + 1), train_losses, label='Train Loss')
plt.plot(range(1, NUM_EPOCHS + 1), test_losses, label='Test Loss')

# Accuracy curves
plt.plot(range(1, NUM_EPOCHS + 1), train_accuracies, label='Train Accuracy')
plt.plot(range(1, NUM_EPOCHS + 1), test_accuracies, label='Test Accuracy')
```

**Interpretaci√≥n de las Gr√°ficas**:

- **Loss decreciente**: El modelo est√° aprendiendo
- **Train accuracy > Test accuracy**: Normal, esperado
- **Gap muy grande**: Posible overfitting
- **Test loss aumentando**: Definitivamente overfitting

**Resultados de este Modelo**:
- Train Accuracy: 96.63%
- Test Accuracy: 68.00%
- Gap grande ‚Üí overfitting presente

---

### 4Ô∏è‚É£ `model/training_metrics.json` - M√©tricas del Entrenamiento

**Prop√≥sito**: Almacena todas las m√©tricas y resultados del entrenamiento.

#### üìä Estructura del JSON

```json
{
    "training_info": {
        "epochs": 25,
        "batch_size": 64,
        "learning_rate": 0.001,
        "optimizer": "Adam",
        "device": "cpu",
        "training_duration_seconds": 3230.94,
        "training_duration_formatted": "0:53:50"
    },
    "model_info": {
        "total_parameters": 1705732,
        "trainable_parameters": 1705732,
        "architecture": "MLP: 3072 -> 512 -> 256 -> 4"
    },
    "final_metrics": {
        "train_loss": 0.1057,
        "train_accuracy": 96.63,
        "test_loss": 2.185,
        "test_accuracy": 68.0
    }
}
```

**An√°lisis de Resultados**:

1. **Train Loss: 0.1057 (bajo)**
   - El modelo ha aprendido muy bien los datos de entrenamiento
   
2. **Test Loss: 2.185 (alto)**
   - En datos nuevos, el modelo tiene m√°s error
   - Indicador claro de overfitting

3. **Train Accuracy: 96.63%**
   - Clasifica correctamente casi todas las im√°genes de entrenamiento

4. **Test Accuracy: 68.0%**
   - En datos nuevos, solo acierta 68%
   - Gap del 28.63% indica memorizaci√≥n vs. generalizaci√≥n

**¬øC√≥mo mejorar esto?**
- Regularizaci√≥n (Dropout, Weight Decay)
- Data Augmentation (rotaciones, flips)
- Modelo m√°s simple (menos par√°metros)
- M√°s datos de entrenamiento

---

### 5Ô∏è‚É£ `backend/main.py` - API FastAPI

**Prop√≥sito**: Servidor HTTP que expone el modelo para hacer predicciones.

#### üöÄ Inicializaci√≥n de FastAPI

```python
app = FastAPI(title="CIFAR-10 MLP Classifier")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

**¬øQu√© es CORS?**
- **Cross-Origin Resource Sharing**
- Permite que el frontend (puerto 3000) acceda al backend (puerto 8000)
- Sin CORS, el navegador bloquear√≠a las peticiones

#### üîß Carga del Modelo

```python
model_path = '/app/model/cifar10_mlp.pth' if os.path.exists('/app/model/cifar10_mlp.pth') \
             else '../model/cifar10_mlp.pth'
checkpoint = torch.load(model_path, map_location=device)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()
```

**¬øPor qu√© dos rutas?**
- `/app/model/cifar10_mlp.pth`: Ruta dentro de Docker
- `../model/cifar10_mlp.pth`: Ruta en desarrollo local
- `map_location=device`: Carga en CPU (para compatibilidad)

#### üîç Endpoint: `/predict`

```python
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    # Leer imagen
    image_bytes = await file.read()
    image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
    
    # Transformar
    image_tensor = transform(image).unsqueeze(0)
    
    # Predecir
    with torch.no_grad():
        outputs = model(image_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        confidence, predicted = torch.max(probabilities, 1)
    
    return {
        "class_id": predicted.item(),
        "class_name": CLASS_NAMES[predicted.item()],
        "confidence": confidence.item(),
        "all_probabilities": probabilities[0].tolist()
    }
```

**Desglose Paso a Paso**:

1. **Recibir Imagen**:
   ```python
   file: UploadFile = File(...)  # FastAPI maneja multipart/form-data
   ```

2. **Convertir a PIL Image**:
   ```python
   image_bytes = await file.read()
   image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
   ```

3. **Aplicar Transformaciones**:
   ```python
   transform = transforms.Compose([
       transforms.Resize((32, 32)),
       transforms.ToTensor(),
       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
   ])
   image_tensor = transform(image).unsqueeze(0)
   ```
   - **Resize**: Asegura que la imagen sea 32x32
   - **unsqueeze(0)**: A√±ade dimensi√≥n de batch [1, 3, 32, 32]

4. **Inferencia**:
   ```python
   outputs = model(image_tensor)  # Logits [1, 4]
   probabilities = torch.nn.functional.softmax(outputs, dim=1)
   ```

**¬øQu√© es Softmax?**
```
Logits: [-2.3, 4.1, 0.5, -1.2]
         ‚Üì Softmax
Probabilities: [0.01, 0.92, 0.03, 0.04]  (suman 1.0)
```
- Convierte logits en probabilidades
- F√≥rmula: `softmax(x_i) = exp(x_i) / Œ£ exp(x_j)`

5. **Extraer Resultado**:
   ```python
   confidence, predicted = torch.max(probabilities, 1)
   ```
   - `predicted`: √çndice de la clase con mayor probabilidad
   - `confidence`: Valor de esa probabilidad

#### üåê Endpoint: `/predict-external`

```python
@app.post("/predict-external")
async def predict_external(file: UploadFile = File(...)):
    original_size = image.size
    original_mode = image.mode
    
    if image.mode != 'RGB':
        image = image.convert('RGB')
    
    image = image.resize((32, 32), Image.LANCZOS)
```

**Diferencias con `/predict`**:
- Acepta im√°genes de **cualquier tama√±o**
- Guarda informaci√≥n del procesamiento
- Convierte autom√°ticamente a RGB (RGBA, grayscale, etc.)
- Usa LANCZOS para mejor calidad al redimensionar

**¬øPor qu√© este endpoint adicional?**
- Permite usar im√°genes de internet o c√°mara
- M√°s flexible para usuarios finales
- Transparente sobre el procesamiento realizado

---

### 6Ô∏è‚É£ `backend/requirements.txt` - Dependencias Backend

```
fastapi         # Framework web moderno
uvicorn         # Servidor ASGI para FastAPI
torch           # PyTorch para deep learning
torchvision     # Transformaciones de im√°genes
python-multipart # Para manejar uploads de archivos
Pillow          # Procesamiento de im√°genes
numpy           # Operaciones num√©ricas
```

**¬øPor qu√© estas librer√≠as?**
- **FastAPI + Uvicorn**: Servidor r√°pido y as√≠ncrono
- **torch + torchvision**: Cargar modelo y preprocesar
- **Pillow**: Abrir y manipular im√°genes
- **python-multipart**: Necesario para UploadFile

---

### 7Ô∏è‚É£ `backend/Dockerfile` - Containerizaci√≥n Backend

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# Copiar requirements
COPY requirements.txt .

# Instalar dependencias
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo del backend
COPY main.py .

# Exponer puerto
EXPOSE 8000

# Comando para ejecutar
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Explicaci√≥n L√≠nea por L√≠nea**:

1. **FROM python:3.10-slim**:
   - Imagen base de Python 3.10
   - `slim`: Versi√≥n ligera (menos librer√≠as)
   - Reduce tama√±o del contenedor

2. **WORKDIR /app**:
   - Establece directorio de trabajo
   - Todos los comandos siguientes se ejecutan aqu√≠

3. **COPY requirements.txt .**:
   - Copia solo requirements primero
   - Aprovecha cach√© de Docker (eficiencia)

4. **RUN pip install --no-cache-dir -r requirements.txt**:
   - Instala dependencias Python
   - `--no-cache-dir`: No guarda cach√©, reduce tama√±o

5. **COPY main.py .**:
   - Copia el c√≥digo del servidor

6. **EXPOSE 8000**:
   - Documenta que el contenedor usa el puerto 8000
   - No abre el puerto (eso lo hace docker-compose)

7. **CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]**:
   - Comando por defecto al iniciar el contenedor
   - `--host 0.0.0.0`: Escucha en todas las interfaces
   - Necesario para acceder desde fuera del contenedor

---

### 8Ô∏è‚É£ `frontend/src/App.js` - Interfaz de Usuario React

**Prop√≥sito**: Aplicaci√≥n web para cargar im√°genes y visualizar predicciones.

#### üé® Estructura de Estados

```javascript
// Estados para el bot√≥n verde (dataset)
const [selectedFile, setSelectedFile] = useState(null);
const [preview, setPreview] = useState(null);
const [loading, setLoading] = useState(false);
const [result, setResult] = useState(null);
const [error, setError] = useState(null);

// Estados para el bot√≥n naranja (externas)
const [externalFile, setExternalFile] = useState(null);
const [externalPreview, setExternalPreview] = useState(null);
const [externalLoading, setExternalLoading] = useState(false);
const [externalResult, setExternalResult] = useState(null);
const [externalError, setExternalError] = useState(null);
```

**¬øQu√© son los estados en React?**
- Variables que cuando cambian, re-renderizan el componente
- `useState`: Hook para crear estado local
- Cada secci√≥n tiene sus propios estados (independientes)

#### üì§ Manejo de Selecci√≥n de Archivo

```javascript
const handleFileSelect = (e) => {
    const file = e.target.files[0];
    if (file) {
        setSelectedFile(file);
        setPreview(URL.createObjectURL(file));  // Vista previa
        setResult(null);  // Limpiar resultado anterior
        setError(null);   // Limpiar error anterior
    }
};
```

**URL.createObjectURL(file)**:
- Crea una URL temporal que apunta al archivo local
- Permite mostrar la imagen sin subirla al servidor
- Se revoca autom√°ticamente al cerrar la p√°gina

#### üöÄ Clasificaci√≥n de Imagen

```javascript
const handleClassify = async () => {
    setLoading(true);
    setError(null);
    
    const formData = new FormData();
    formData.append('file', selectedFile);
    
    try {
        const response = await axios.post('http://localhost:8000/predict', 
                                         formData, {
            headers: { 'Content-Type': 'multipart/form-data' }
        });
        setResult(response.data);
    } catch (err) {
        setError('Error al clasificar la imagen: ' + err.message);
    } finally {
        setLoading(false);
    }
};
```

**Flujo de la Petici√≥n**:

1. **setLoading(true)**: Muestra "Clasificando..."
2. **FormData**: Formato para enviar archivos
3. **axios.post**: Petici√≥n HTTP POST al backend
4. **response.data**: JSON con la predicci√≥n
5. **setResult**: Actualiza UI con el resultado
6. **finally**: Se ejecuta siempre, success o error

#### üìä Visualizaci√≥n de Top 3

```javascript
const getTop3 = () => {
    const probs = result.all_probabilities.map((prob, idx) => ({
        class_name: CLASS_NAMES[idx],
        probability: prob,
    }));
    
    return probs.sort((a, b) => b.probability - a.probability)
                .slice(0, 3);
};
```

**¬øQu√© hace?**
1. Combina probabilidades con nombres de clase
2. Ordena de mayor a menor probabilidad
3. Toma solo los 3 primeros
4. Retorna array: `[{class_name, probability}, ...]`

#### üé® Renderizado de Resultados

```javascript
{result && (
    <div style={styles.resultSection}>
        <h2>Resultado</h2>
        <p style={styles.className}>{result.class_name}</p>
        <p style={styles.confidence}>
            Confianza: {(result.confidence * 100).toFixed(2)}%
        </p>
        
        <h3>Top 3 Predicciones:</h3>
        {getTop3().map((item, idx) => (
            <div key={idx}>
                <span>{item.class_name}</span>
                <span>{(item.probability * 100).toFixed(2)}%</span>
            </div>
        ))}
    </div>
)}
```

**Renderizado Condicional**:
- `{result && ...}`: Solo renderiza si `result` existe
- Previene errores cuando no hay resultado a√∫n

#### üé® Estilos CSS-in-JS

```javascript
const styles = {
    container: {
        maxWidth: '800px',
        margin: '50px auto',
        padding: '20px',
        fontFamily: 'Arial, sans-serif',
    },
    uploadButton: {
        backgroundColor: '#4CAF50',  // Verde
        color: 'white',
        padding: '12px 24px',
        borderRadius: '4px',
        cursor: 'pointer',
    },
    uploadButtonExternal: {
        backgroundColor: '#FF9800',  // Naranja
        // ... similar
    }
};
```

**¬øPor qu√© CSS-in-JS?**
- Estilos viven con el componente
- No hay conflictos de nombres de clases
- F√°cil de mantener para proyectos peque√±os

---

### 9Ô∏è‚É£ `frontend/src/index.js` - Punto de Entrada

```javascript
import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App';

const root = ReactDOM.createRoot(document.getElementById('root'));
root.render(<App />);
```

**¬øQu√© hace este archivo?**
1. Importa React y ReactDOM
2. Crea un "root" React en el div con id="root"
3. Renderiza el componente `<App />` dentro del root
4. React toma control de ese div y gestiona el DOM

---

### üîü `frontend/public/index.html` - HTML Base

```html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>CIFAR-10 Classifier</title>
  </head>
  <body>
    <div id="root"></div>
  </body>
</html>
```

**Simplicidad**:
- Solo un div: `<div id="root"></div>`
- React inyecta toda la app ah√≠
- No hay CSS, JS inline ‚Üí todo gestionado por React

---

### 1Ô∏è‚É£1Ô∏è‚É£ `frontend/package.json` - Dependencias Frontend

```json
{
  "name": "cifar10-frontend",
  "version": "1.0.0",
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "axios": "^1.6.0"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build"
  },
  "devDependencies": {
    "react-scripts": "5.0.1"
  }
}
```

**Dependencias Clave**:

- **react**: Librer√≠a principal
- **react-dom**: Integraci√≥n con el DOM del navegador
- **axios**: Cliente HTTP para peticiones al backend
- **react-scripts**: Herramientas de desarrollo (webpack, babel, etc.)

**Scripts**:
- `npm start`: Inicia servidor de desarrollo (puerto 3000)
- `npm build`: Crea versi√≥n optimizada para producci√≥n

---

### 1Ô∏è‚É£2Ô∏è‚É£ `frontend/Dockerfile` - Containerizaci√≥n Frontend

```dockerfile
FROM node:18-alpine

WORKDIR /app

COPY package.json .
RUN npm install

COPY public ./public
COPY src ./src

EXPOSE 3000

CMD ["npm", "start"]
```

**Diferencias con Backend Dockerfile**:

1. **Imagen base**: `node:18-alpine` (Node.js en vez de Python)
2. **Gesti√≥n de dependencias**: `npm install` en vez de `pip`
3. **Puerto**: 3000 (est√°ndar para React)
4. **Comando**: `npm start` (servidor de desarrollo)

**alpine**:
- Distribuci√≥n Linux muy ligera
- Reduce tama√±o de la imagen Docker
- ~5MB vs ~100MB para im√°genes base completas

---

### 1Ô∏è‚É£3Ô∏è‚É£ `docker-compose.yml` - Orquestaci√≥n de Contenedores

```yaml
services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    volumes:
      - ./model:/app/model:ro
    restart: always
    networks:
      - cifar10-network

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend
    restart: always
    networks:
      - cifar10-network

networks:
  cifar10-network:
    driver: bridge
```

**Explicaci√≥n Detallada**:

#### Backend Service

```yaml
backend:
  build: ./backend  # Construye Dockerfile en ./backend
  ports:
    - "8000:8000"  # Host:Container
  volumes:
    - ./model:/app/model:ro  # Montar carpeta model (read-only)
```

**Volumen ./model**:
- Monta la carpeta local `./model` dentro del contenedor en `/app/model`
- `:ro` = read-only (solo lectura)
- Permite al backend acceder al modelo sin copiarlo al contenedor
- Cambios en el modelo se reflejan inmediatamente

#### Frontend Service

```yaml
frontend:
  build: ./frontend
  ports:
    - "3000:3000"
  depends_on:
    - backend  # Espera que backend est√© listo
```

**depends_on**:
- Asegura que backend inicie primero
- No espera que backend est√© "listo", solo que inicie
- Para esperar que est√© listo, se necesita healthcheck

#### Network

```yaml
networks:
  cifar10-network:
    driver: bridge
```

**¬øQu√© es una red bridge?**
- Red virtual privada entre contenedores
- Permite que contenedores se comuniquen por nombre
- Aislado del host (seguridad)

**Comunicaci√≥n**:
- Frontend puede acceder a backend como `http://backend:8000`
- Pero desde el navegador se usa `http://localhost:8000` (fuera de Docker)

---

### 1Ô∏è‚É£4Ô∏è‚É£ `PLAN.md` - Plan de Implementaci√≥n

**Prop√≥sito**: Documento de planificaci√≥n y roadmap del proyecto.

#### Contenido Principal

1. **Objetivo del Proyecto**
2. **Arquitectura Propuesta**
3. **Pasos de Implementaci√≥n**:
   - Fase 1: Preparaci√≥n del Dataset
   - Fase 2: Modelo MLP
   - Fase 3: Backend FastAPI
   - Fase 4: Frontend React
   - Fase 5: Dockerizaci√≥n
   - Fase 6: Testing
4. **Detalles T√©cnicos** de cada componente
5. **Endpoints** de la API
6. **Comandos** para ejecutar

**Utilidad**:
- Sirve como referencia durante el desarrollo
- Documenta decisiones de dise√±o
- Facilita onboarding de nuevos desarrolladores

---

## üîÑ Flujo de Datos Completo

### Flujo de Predicci√≥n End-to-End

```
1. USUARIO
   ‚îÇ
   ‚îî‚îÄ‚Üí Selecciona imagen en navegador
       ‚îÇ
       ‚îî‚îÄ‚Üí [Frontend: App.js]
           ‚îÇ
           ‚îî‚îÄ‚Üí handleClassify() crea FormData
               ‚îÇ
               ‚îî‚îÄ‚Üí axios.post('http://localhost:8000/predict')
                   ‚îÇ
2. BACKEND
   ‚îÇ
   ‚îî‚îÄ‚Üí [Backend: main.py]
       ‚îÇ
       ‚îú‚îÄ‚Üí Recibe imagen (FastAPI)
       ‚îú‚îÄ‚Üí Convierte a PIL Image
       ‚îú‚îÄ‚Üí Aplica transformaciones (resize, normalize)
       ‚îú‚îÄ‚Üí Convierte a tensor [1, 3, 32, 32]
       ‚îÇ
       ‚îî‚îÄ‚Üí [Modelo: MLP]
           ‚îÇ
           ‚îú‚îÄ‚Üí Forward pass
           ‚îÇ   ‚îî‚îÄ‚Üí fc1(3072 -> 512) + ReLU
           ‚îÇ       ‚îî‚îÄ‚Üí fc2(512 -> 256) + ReLU
           ‚îÇ           ‚îî‚îÄ‚Üí fc3(256 -> 4)
           ‚îÇ
           ‚îú‚îÄ‚Üí Logits: [-2.3, 4.1, 0.5, -1.2]
           ‚îú‚îÄ‚Üí Softmax: [0.01, 0.92, 0.03, 0.04]
           ‚îî‚îÄ‚Üí Predicci√≥n: clase 1 (automobile), 92% confianza
               ‚îÇ
3. RESPUESTA
   ‚îÇ
   ‚îî‚îÄ‚Üí JSON: {
           "class_id": 1,
           "class_name": "automobile",
           "confidence": 0.92,
           "all_probabilities": [0.01, 0.92, 0.03, 0.04]
       }
       ‚îÇ
4. FRONTEND
   ‚îÇ
   ‚îî‚îÄ‚Üí setResult(response.data)
       ‚îÇ
       ‚îî‚îÄ‚Üí Re-renderiza UI
           ‚îÇ
           ‚îú‚îÄ‚Üí Muestra "AUTOMOBILE"
           ‚îú‚îÄ‚Üí Muestra "Confianza: 92.00%"
           ‚îî‚îÄ‚Üí Muestra Top 3:
               1. automobile: 92.00%
               2. ship: 3.00%
               3. truck: 4.00%
```

---

## üí° Conceptos Importantes Explicados

### 1. Red Neuronal Artificial (MLP)

**¬øQu√© es?**
- Sistema de procesamiento inspirado en el cerebro
- Compuesto por capas de neuronas artificiales
- Aprende patrones a partir de ejemplos

**Componentes**:
```
Neurona: f(Œ£(w_i * x_i) + b)
         ‚îÇ   ‚îÇ    ‚îÇ     ‚îÇ
         ‚îÇ   ‚îÇ    ‚îÇ     ‚îî‚îÄ bias
         ‚îÇ   ‚îÇ    ‚îî‚îÄ input
         ‚îÇ   ‚îî‚îÄ peso
         ‚îî‚îÄ funci√≥n de activaci√≥n
```

**Proceso de Aprendizaje**:
1. Inicializaci√≥n aleatoria de pesos
2. Forward pass: Calcular predicci√≥n
3. Calcular error (loss)
4. Backward pass: Calcular gradientes
5. Actualizar pesos para reducir error
6. Repetir hasta convergencia

### 2. Overfitting vs Underfitting

**Overfitting** (Sobreajuste):
- El modelo memoriza los datos de entrenamiento
- Funciona muy bien en train, mal en test
- **S√≠ntomas**:
  - Train accuracy >> Test accuracy
  - Train loss << Test loss
- **Este proyecto**: 96.63% train vs 68% test

**Underfitting** (Subajuste):
- El modelo no aprende suficiente
- Funciona mal en train y test
- **S√≠ntomas**:
  - Train accuracy baja
  - Test accuracy tambi√©n baja

**Balance Ideal**:
- Train accuracy ‚âà Test accuracy
- Generalizaci√≥n a datos nuevos

### 3. Batch Processing

**¬øPor qu√© procesar en batches?**

**Sin Batches** (Stochastic Gradient Descent):
```
Para cada imagen:
    - Forward pass
    - Backward pass
    - Actualizar pesos
```
- Muy lento
- Actualizaci√≥n ruidosa

**Con Batches**:
```
Para cada batch de 64 im√°genes:
    - Forward pass en paralelo
    - Calcular loss promedio
    - Backward pass
    - Actualizar pesos una vez
```
- Mucho m√°s r√°pido (GPU parallelization)
- Actualizaciones m√°s estables
- Uso eficiente de memoria

### 4. Learning Rate

**¬øQu√© controla?**
- Tama√±o del paso al actualizar pesos
- `new_weight = old_weight - lr * gradient`

**Demasiado Alto** (lr > 0.01):
```
Loss
‚îÇ     *
‚îÇ    * *
‚îÇ   *   *
‚îÇ  *     *
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Iteraciones
No converge, oscila
```

**Demasiado Bajo** (lr < 0.0001):
```
Loss
‚îÇ*
‚îÇ *
‚îÇ  *
‚îÇ   *___________
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Iteraciones
Muy lento, puede estancarse
```

**√ìptimo** (lr ‚âà 0.001):
```
Loss
‚îÇ*
‚îÇ **
‚îÇ   ***
‚îÇ      ****______
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Iteraciones
Converge suavemente
```

### 5. Softmax y Probabilidades

**Funci√≥n Softmax**:
```python
def softmax(x):
    exp_x = np.exp(x - np.max(x))  # Estabilidad num√©rica
    return exp_x / exp_x.sum()
```

**Ejemplo**:
```
Input (logits):  [-2.3,  4.1,  0.5, -1.2]
                    ‚Üì exp()
                 [0.10, 60.3, 1.65, 0.30]
                    ‚Üì normalize
Output (probs):  [0.002, 0.966, 0.026, 0.005]
                    ‚Üì sum = 1.0
```

**Propiedades**:
- Todas las probabilidades suman 1.0
- Amplifica diferencias (4.1 >> otros)
- Siempre positivas

### 6. Cross-Entropy Loss

**¬øQu√© mide?**
- Qu√© tan "lejos" est√° la predicci√≥n de la realidad

**F√≥rmula**:
```
Loss = -Œ£ y_true * log(y_pred)

Para clasificaci√≥n:
Loss = -log(P(clase_correcta))
```

**Ejemplo**:
```
Imagen real: automobile (clase 1)
Predicciones: [0.01, 0.92, 0.03, 0.04]

Loss = -log(0.92) = 0.083
```

**Interpretaci√≥n**:
- Predicci√≥n correcta con 99% ‚Üí Loss ‚âà 0.01
- Predicci√≥n correcta con 50% ‚Üí Loss ‚âà 0.69
- Predicci√≥n correcta con 10% ‚Üí Loss ‚âà 2.30

### 7. Docker y Containerizaci√≥n

**¬øQu√© es un contenedor?**
- Paquete autocontenido con aplicaci√≥n + dependencias
- Aislado del sistema host
- Garantiza: "Funciona en mi m√°quina" = "Funciona en todas"

**Ventajas**:
- **Portabilidad**: Funciona igual en cualquier m√°quina
- **Aislamiento**: No interfiere con otras aplicaciones
- **Reproducibilidad**: Mismo ambiente siempre
- **Escalabilidad**: F√°cil de replicar

**Docker vs VM**:
```
Virtual Machine:
[App] ‚Üí [Guest OS] ‚Üí [Hypervisor] ‚Üí [Host OS] ‚Üí [Hardware]
Pesado, lento

Docker Container:
[App] ‚Üí [Docker Engine] ‚Üí [Host OS] ‚Üí [Hardware]
Ligero, r√°pido
```

### 8. API REST

**¬øQu√© es REST?**
- **RE**presentational **S**tate **T**ransfer
- Arquitectura para APIs web
- Usa verbos HTTP: GET, POST, PUT, DELETE

**Caracter√≠sticas**:
- **Stateless**: Cada petici√≥n es independiente
- **Client-Server**: Separaci√≥n de responsabilidades
- **Cacheable**: Respuestas pueden ser cacheadas
- **Uniform Interface**: URLs y m√©todos est√°ndar

**Ejemplo en este proyecto**:
```
POST /predict
Content-Type: multipart/form-data
Body: [imagen]

‚Üí Backend procesa

Response:
{
  "class_name": "airplane",
  "confidence": 0.85
}
```

---

## üöÄ Instalaci√≥n y Uso

### Opci√≥n 1: Con Docker (Recomendado)

```bash
# 1. Clonar o tener el proyecto
cd cifar10/

# 2. Preparar el dataset (solo primera vez)
python prepare_dataset.py

# 3. Entrenar el modelo (solo primera vez)
cd model/
python train.py
cd ..

# 4. Iniciar con Docker Compose
docker-compose up --build

# Acceder:
# - Frontend: http://localhost:3000
# - Backend: http://localhost:8000
```

### Opci√≥n 2: Sin Docker (Desarrollo Local)

**Backend**:
```bash
cd backend/
pip install -r requirements.txt
python main.py
```

**Frontend** (en otra terminal):
```bash
cd frontend/
npm install
npm start
```

### Comandos √ötiles

```bash
# Ver logs de contenedores
docker-compose logs -f

# Detener contenedores
docker-compose down

# Reconstruir desde cero
docker-compose up --build --force-recreate

# Acceder a un contenedor
docker-compose exec backend bash
```

---

## üìä M√©tricas y Rendimiento

### Resultados del Entrenamiento

| M√©trica | Train | Test | Diferencia |
|---------|-------|------|------------|
| **Accuracy** | 96.63% | 68.00% | -28.63% |
| **Loss** | 0.106 | 2.185 | +2.079 |

### Interpretaci√≥n

**Accuracy por Clase** (estimado):
- Airplane: ~70%
- Automobile: ~75%
- Ship: ~65%
- Truck: ~62%

**Problemas Detectados**:
1. **Overfitting severo**: Gap del 28% entre train y test
2. **Modelo simple**: MLP no es ideal para im√°genes
3. **Sin regularizaci√≥n**: No hay Dropout ni Weight Decay

### Mejoras Posibles

1. **Arquitectura**:
   - Usar CNN en vez de MLP
   - CNNs son mejores para im√°genes (capturan patrones espaciales)

2. **Regularizaci√≥n**:
   - A√±adir Dropout (0.3-0.5)
   - Weight Decay en el optimizador
   - Early Stopping

3. **Data Augmentation**:
   - Rotaciones aleatorias
   - Flips horizontales
   - Cambios de brillo/contraste

4. **M√°s Datos**:
   - Usar las 10 clases completas
   - Aumentar dataset con augmentation

---

## üîí Seguridad y Consideraciones

### Seguridad

1. **CORS Abierto**:
   ```python
   allow_origins=["*"]  # Permite cualquier origen
   ```
   - **Problema**: Cualquier sitio web puede acceder
   - **Soluci√≥n**: Restringir a dominios espec√≠ficos en producci√≥n

2. **Sin Autenticaci√≥n**:
   - Endpoints p√∫blicos sin protecci√≥n
   - **Soluci√≥n**: A√±adir API keys o JWT

3. **Validaci√≥n de Entrada**:
   - Solo valida tipo de archivo
   - **Soluci√≥n**: Validar tama√±o, formato, contenido

### Escalabilidad

**Limitaciones Actuales**:
- Un solo worker (uvicorn)
- Inferencia s√≠ncrona (bloquea mientras predice)
- Sin cach√© de resultados

**Mejoras**:
- Usar Gunicorn + m√∫ltiples workers
- Cola de tareas (Celery + Redis)
- Cach√© para im√°genes ya procesadas

### Monitoreo

**M√©tricas a Trackear**:
- Latencia de predicciones
- Tasa de errores
- Uso de memoria/CPU
- Distribuci√≥n de clases predichas

**Herramientas**:
- Prometheus + Grafana
- Sentry para errores
- Logs estructurados (JSON)

---

## üìñ Glosario de T√©rminos

| T√©rmino | Definici√≥n |
|---------|-----------|
| **MLP** | Multi-Layer Perceptron, red neuronal fully-connected |
| **Epoch** | Pasar por todo el dataset de entrenamiento una vez |
| **Batch** | Subconjunto de datos procesados simult√°neamente |
| **Learning Rate** | Tama√±o del paso en la optimizaci√≥n |
| **Overfitting** | Modelo memoriza en vez de generalizar |
| **Forward Pass** | C√°lculo de predicci√≥n (entrada ‚Üí salida) |
| **Backward Pass** | C√°lculo de gradientes (backpropagation) |
| **Logits** | Valores crudos antes de softmax |
| **Softmax** | Convierte logits en probabilidades |
| **Cross-Entropy** | Funci√≥n de p√©rdida para clasificaci√≥n |
| **Adam** | Algoritmo de optimizaci√≥n adaptativo |
| **ReLU** | Funci√≥n de activaci√≥n: max(0, x) |
| **Inference** | Usar el modelo para hacer predicciones |
| **Checkpoint** | Snapshot del modelo guardado |
| **Tensor** | Array multidimensional (PyTorch) |
| **Gradient** | Derivada del loss respecto a pesos |

---

## üéì Recursos Adicionales

### Documentaci√≥n Oficial
- [PyTorch Documentation](https://pytorch.org/docs/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [React Documentation](https://react.dev/)
- [Docker Documentation](https://docs.docker.com/)

### Tutoriales Recomendados
- [PyTorch 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)
- [3Blue1Brown - Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- [Stanford CS231n - CNN for Visual Recognition](http://cs231n.stanford.edu/)

### Papers Relevantes
- [ImageNet Classification with Deep CNNs (AlexNet)](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)
- [Adam Optimizer Paper](https://arxiv.org/abs/1412.6980)

---

## üìù Conclusiones

Este proyecto implementa un clasificador de im√°genes completo, desde la preparaci√≥n de datos hasta el despliegue con Docker. Aunque el modelo MLP tiene limitaciones (overfitting, arquitectura simple), sirve como base excelente para:

1. **Aprender** los fundamentos de deep learning
2. **Entender** el ciclo completo de un proyecto ML
3. **Experimentar** con mejoras (CNN, regularizaci√≥n, etc.)
4. **Deployar** modelos con APIs modernas

El proyecto est√° bien estructurado, documentado y listo para ser extendido con mejoras m√°s avanzadas.

---

**√öltima actualizaci√≥n**: Octubre 2025  
**Autor**: Proyecto CIFAR-10 MLP Classifier  
**Licencia**: Uso educativo
